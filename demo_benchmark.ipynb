{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from __future__ import division\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pprint\n",
    "import random\n",
    "import numpy as np\n",
    "import PIL.Image as pil\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import cv2\n",
    "\n",
    "\n",
    "import tensorflow.contrib.slim.nets\n",
    "\n",
    "from imageselect_Dataloader_optflow import DataLoader\n",
    "import os\n",
    "\n",
    "from nets_optflow_depth import *\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "FLAGS.dataset_dir = \"./data\"\n",
    "FLAGS.output_dir = \"./output/\"\n",
    "FLAGS.image_height = 192\n",
    "FLAGS.image_width = 256\n",
    "FLAGS = flags.FLAGS\n",
    "FLAGS.resizedheight = 192\n",
    "FLAGS.resizedwidth = 256\n",
    "FLAGS.checkpoint_dir=\"./checkpoints\"\n",
    "FLAGS.checkpoint_dir_single=\"./checkpoints_single\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():\n",
    "    #Load image and label\n",
    "    imgleft = tf.placeholder(shape=[1, FLAGS.resizedheight, FLAGS.resizedwidth, 3], dtype=tf.float32)\n",
    "    imgright = tf.placeholder(shape=[1, FLAGS.resizedheight, FLAGS.resizedwidth, 3], dtype=tf.float32)\n",
    "    \n",
    "        # # Define the model:\n",
    "#     with tf.variable_scope(\"model_pairdepth\") as scope:\n",
    "\n",
    "#         inputdata = tf.concat([imgleft, imgright], axis=3)\n",
    "\n",
    "#         pred_depth_left, pred_poses_right, pred_exp_logits_left, depth_net_endpoints_left = depth_net(inputdata,                                                    \n",
    "#                                                                                             is_training=False)\n",
    "#         saver_pair = tf.train.Saver(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'model_pairdepth'))\n",
    "#         #saver_pair = tf.train.Saver([var for var in tf.model_variables()])\n",
    "#         checkpoint_pair = tf.train.latest_checkpoint(FLAGS.checkpoint_dir)\n",
    "\n",
    "\n",
    "    with tf.variable_scope(\"model_singledepth\") as scope:\n",
    "\n",
    "\n",
    "        #estimate depth and optical flow from both left and right image\n",
    "#         _, height, width, _ = imgleft.get_shape().as_list()\n",
    "\n",
    "#         pred_depth_left_up = tf.image.resize_nearest_neighbor(pred_depth_left[0], [height, width])\n",
    "\n",
    "#         inputdata_single = tf.concat([pred_depth_left_up,imgleft], axis=3)\n",
    "        pred_depth_single_left,depth_endpoints = disp_net(imgleft,                                                 \n",
    "                                              is_training=False)\n",
    "\n",
    "        saver_single = tf.train.Saver(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'model_singledepth'))\n",
    "\n",
    "        checkpoint_single = tf.train.latest_checkpoint(FLAGS.checkpoint_dir_single)                \n",
    "\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        tf.initialize_all_variables().run()\n",
    "        tf.initialize_local_variables().run()\n",
    "\n",
    "        #saver_pair.restore(sess, checkpoint_pair)\n",
    "        saver_single.restore(sess,checkpoint_single)\n",
    "\n",
    "        img_list = sorted(glob(FLAGS.dataset_dir + '/*.jpg'))\n",
    "\n",
    "\n",
    "        #import pdb;pdb.set_trace()\n",
    "        for i in range(len(img_list)-1):\n",
    "\n",
    "            I = Image.open(img_list[i])\n",
    "            I1 = Image.open(img_list[i+1])\n",
    "            I = I.resize((FLAGS.resizedwidth, FLAGS.resizedheight),pil.ANTIALIAS)\n",
    "            I1 = I1.resize((FLAGS.resizedwidth, FLAGS.resizedheight),pil.ANTIALIAS)\n",
    "            # I = np.array(I)\n",
    "            # I1 = np.array(I1)\n",
    "\n",
    "            # I = I.astype(np.float32)\n",
    "            # I1 = I1.astype(np.float32)\n",
    "\n",
    "            I = np.array(I).astype(np.float32)/255.0 -0.5\n",
    "            I1 = np.array(I1).astype(np.float32)/255.0 -0.5\n",
    "            #import pdb;pdb.set_trace()\n",
    "\n",
    "            #inputdata = np.concatenate([I[np.newaxis,:],I1[np.newaxis,:]],axis=3)\n",
    "\n",
    "            pred_single = sess.run(pred_depth_single_left,feed_dict={imgleft: I[np.newaxis,:],\n",
    "                                                                     imgright: I1[np.newaxis,:],\n",
    "                                                                     })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
